# Improving Deep Neural Networks

This repository contains my work for the second course of **Deep Learning Specialization**, *Improving Deep Neural Networks*.

It covers the fundamental concepts of improving neural networks, including initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking. Along with those, implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop, and Adm. The notebooks focus on building core idea from scratch using NumPy, with an emphasis on understannding the underlying mathematic and algorithms. In wee03, I have implented a neural network in TensorFlow. 


## Repository Structure

The repository is organize following the course schedule, with each folder corresponding to one week of the course

- **week01/**
  - Assignment 1: Initialization
  - Assignment 2: Regularization
  - Assignment 3: Gradient checking

- **week02/**
  - Assignment 1: Optimization methods 

- **week04/**
  - Assignment 1: Hyperparmeter tuning, Batch Normalization, Programming Frameworks (Tensorflow)

# How to Run the notebooks

### Prerequisites

- Python 3.x
- Numpy
- Matplotlib
